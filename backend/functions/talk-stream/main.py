import json
import uuid
import logging
import os
import sys
from datetime import datetime
import asyncio
import functions_framework
from flask import Response
from auth_utils import validate_authentication
from firestore_utils import get_config
from google.adk.agents import Agent
from google.adk.runners import InMemoryRunner
from google.genai import types
from google.adk.tools import google_search


# Robust logging setup that works on Cloud Functions/Cloud Run
_level_name = os.environ.get("LOG_LEVEL", "DEBUG").upper()
_level = getattr(logging, _level_name, logging.DEBUG)
_root = logging.getLogger()
_root.setLevel(_level)
if not any(isinstance(h, logging.StreamHandler) for h in _root.handlers):
    _handler = logging.StreamHandler(sys.stdout)
    _formatter = logging.Formatter(
        "%(levelname)s:%(name)s:%(asctime)s:%(message)s"
    )
    _handler.setFormatter(_formatter)
    _handler.setLevel(_level)
    _root.addHandler(_handler)
logger = logging.getLogger(__name__)
logger.setLevel(_level)


# Initialize the ADK agent with Gemini 2.5 Flash
def create_agent():
    """Create and return an ADK agent for conversation."""
    return Agent(
        model='gemini-2.5-flash',
        name='classroom_assistant',
        description=(
            "A helpful classroom assistant "
            "that answers student questions."
        ),
        instruction=(
            "You are Xiaoice, a friendly and helpful classroom assistant. "
            "Respond to student questions in a clear, educational, and "
            "encouraging manner. "
            "Keep responses concise but informative."
        ),
        tools=[google_search]
    )


# Create runner (reusable across requests)
agent = create_agent()
runner = InMemoryRunner(
    agent=agent,
    app_name='xiaoice_classroom_assistant',
)


@functions_framework.http
def talk_stream(request):
    """Streaming SSE response that mirrors the reference pattern.
    Yields incremental chunks followed by a final summary chunk.
    """
    logger.debug("talk_stream invoked")
    auth_error = validate_authentication(request)
    if auth_error:
        logger.warning("auth_error: %s", auth_error)
        return auth_error

    request_json = request.get_json(silent=True) or {}
    logger.debug("request_json: %s", request_json)

    ask_text = request_json.get("askText", "")
    session_id = request_json.get("sessionId", str(uuid.uuid4()))
    trace_id = request_json.get("traceId", str(uuid.uuid4()))
    language_code = request_json.get("languageCode", "en")
    extra = request_json.get("extra", {})

    def sse_format(obj: dict) -> str:
        return f"data: {json.dumps(obj, ensure_ascii=False)}\n\n"

    def stream_response():
        # Prepare the prompt with language context
        prompt = ask_text
        if language_code and language_code != "en":
            prompt = f"Please respond in {language_code}: {ask_text}"

        try:
            # Create a session for this conversation
            session = asyncio.run(
                runner.session_service.create_session(
                    app_name='xiaoice_classroom_assistant',
                    user_id=session_id,
                )
            )
            logger.debug("Session created: %s", getattr(session, 'id', None))

            content = types.Content(
                role='user',
                parts=[types.Part.from_text(text=prompt)]
            )

            accumulated_text = ""
            for event in runner.run(
                user_id=session_id,
                session_id=getattr(session, 'id', None),
                new_message=content,
            ):
                try:
                    text = ""
                    if getattr(event, "content", None) and event.content.parts:
                        part0 = event.content.parts[0]
                        text = getattr(part0, "text", "") or ""
                    if not text:
                        continue
                    accumulated_text += text
                    chunk = {
                        "askText": ask_text,
                        "extra": extra,
                        "id": trace_id,
                        "replyPayload": None,
                        "replyText": text,  # incremental piece
                        "replyType": "Llm",
                        "sessionId": session_id,
                        "timestamp": int(datetime.now().timestamp() * 1000),
                        "traceId": trace_id,
                        "isFinal": False,
                    }
                    logger.debug("Streaming chunk (%s chars)", len(text))
                    yield sse_format(chunk)
                except Exception:
                    logger.exception("Error while streaming a chunk")
            # Final chunk
            final_chunk = {
                "askText": ask_text,
                "extra": extra,
                "id": trace_id,
                "replyPayload": None,
                "replyText": accumulated_text,
                "replyType": "Llm",
                "sessionId": session_id,
                "timestamp": int(datetime.now().timestamp() * 1000),
                "traceId": trace_id,
                "isFinal": True,
            }
            logger.debug("Final chunk length: %s", len(accumulated_text))
            yield sse_format(final_chunk)
        except Exception:
            logger.exception("Error generating agent response; using fallback")
            # Fallback to config-based response on error
            config = get_config()
            talk_responses = config.get("talk_responses", {})
            default_response = f"Mock response to: {ask_text}"
            response_text = talk_responses.get(
                language_code, talk_responses.get("en", default_response)
            )
            err_chunk = {
                "askText": ask_text,
                "extra": extra,
                "id": trace_id,
                "replyPayload": None,
                "replyText": response_text,
                "replyType": "Llm",
                "sessionId": session_id,
                "timestamp": int(datetime.now().timestamp() * 1000),
                "traceId": trace_id,
                "isFinal": True,
            }
            yield sse_format(err_chunk)

    headers = {
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
        "Access-Control-Allow-Origin": "*",
        "X-Accel-Buffering": "no",
    }
    return Response(stream_response(), mimetype="text/event-stream", headers=headers)
