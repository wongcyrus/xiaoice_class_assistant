# Backend Seeds

This directory contains scripts to seed the backend with course content, simulating the "upload" and "processing" flow locally or against the cloud environment.

## `seed_course_content.py`

This script is a versatile tool that:
1.  **Creates or Updates a Course** in Firestore directly (using Admin privileges).
2.  **Processes Presentation Slides** found in a specified data directory (by default `backend/seeds/generate`).
3.  **Generates Content Locally**: Instead of calling the remote API, it imports the backend logic (`functions/config/message_generator.py` and `functions/config/course_utils.py`) directly to generate AI summaries and synthesize audio using Google Cloud APIs.
4.  **Simulates Broadcast**: It writes the resulting "live" state directly to the Client Firestore, mimicking the behavior of the real backend during a live class.

### Prerequisites

1.  **Python Environment**: Ensure you are in the backend virtual environment or have the dependencies from `backend/requirements.txt` installed.
2.  **Google Cloud Credentials**: Your environment must be authenticated with Google Cloud (e.g., `gcloud auth application-default login`) and have permissions for Firestore, Cloud Storage, and Text-to-Speech.
3.  **Infrastructure Config**: The script relies on `backend/cdktf_outputs.json` (generated by `deploy.sh` or `cdktf apply`) to know the project IDs and bucket names.

### Usage

Run from the `backend` directory:

```bash
# Navigate to backend
cd backend

# Run with default settings (Seeds "Showcase" course with data from 'generate' folder)
python seeds/seed_course_content.py
```

### Customization Arguments

You can customize the seeding process for different courses or data sets:

*   `--course-id`: The ID of the course to create/update (default: `showcase`).
*   `--course-title`: The display title of the course (default: `Showcase`).
*   `--data-dir`: The directory containing the generated source files (relative to `backend/seeds` or absolute path). Default is `generate`.
*   `--languages`: A space-separated list of language codes to generate (default: `en-US zh-CN yue-HK`).
*   `--skip-create`: If set, skips the initial course creation step in Firestore.

**Example: Seeding a Custom Course**

```bash
python seeds/seed_course_content.py \
  --course-id "IT523504Q" \
  --course-title "Certificate in Data Centre Management and Operations Foundation for Public Sector" \
  --data-dir "/home/developer/Documents/data-disk/gemini-powerpoint-sage/notes"
```

### Data Directory Structure

The script expects the folder pointed to by `--data-dir` to follow this structure (generated by the PPT preprocessing pipeline):

```text
/path/to/data-dir/ (e.g., gemini-powerpoint-sage/notes)
├── lecture1_en_progress.json              <-- REQUIRED: Master structure file (English)
├── lecture1_zh-CN_progress.json           <-- Optional: Pre-translated Chinese text
├── lecture1_yue-HK_progress.json          <-- Optional: Pre-translated Cantonese text
├── lecture1_with_visuals.pptm             <-- Optional: Used for filename/ID reference
└── lecture1_visuals/                      <-- Optional: Generated images for slides
    ├── slide_1_reimagined.png
    ├── slide_2_reimagined.png
    └── ...
```

*   **`{basename}_en_progress.json`**: This is the primary file. It must contain the list of slides and the original English speaker notes (`original_notes`). The script loops through this to find all slides.
*   **`{basename}_{suffix}_progress.json`**: If these exist, the script reads the `note` field from them to use as the translated text. If missing, the script calls the AI Agent to generate it.
*   **`{basename}_visuals/`**: If this folder exists, the script looks for `slide_{N}_reimagined.png` and uploads it to Cloud Storage, linking it to the slide broadcast.

### What happens?

1.  **Course Setup**: Creates the course document in the backend Firestore with the specified voice configurations.
2.  **File Discovery**: Scans the data directory for `*_en_progress.json` files to identify presentations.
3.  **Slide Processing**: For each slide:
    *   It reads the speaker notes.
    *   Checks for pre-generated text in the progress JSONs.
    *   If not found, calls the AI Message Generator to create a summary/script.
    *   Synthesizes speech (MP3) using Google Cloud TTS and uploads it to the `speech-file-bucket`.
    *   Uploads any found visual images to the bucket.
4.  **Broadcast**: Updates the Client Firestore `presentation_broadcast` collection with the new slide data, effectively "publishing" it for the student client.
5.  **Live Pointer**: Finally, it sets the "live" pointer to the first slide of the last processed presentation, so the client app displays content immediately upon connection.
